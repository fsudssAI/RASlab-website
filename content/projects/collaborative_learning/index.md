---
layout: page
title: Collaborative Learning

event:
event_url:

location: 
address:
  street: 
  city:
  region:
  postcode:
  country:

summary: The past few decades have seen a tremendous increase in the volume and complexity of data generated in scientific discovery processes. Moreover, due to the rapid growth in internet and networking technology, it is now common for these experiments to be composed of geographically dispersed components. Each of the components generates and stores a huge dataset which captures only a portion of the global phenomenon in question. This poses a tremendous challenge for data analysis, even with the most advanced Machine Learning/ AI methods. The state-of-the-art approaches to this problem involve either routing data to a trusted central location where the learning task takes place or iteratively performing the learning task over the dispersed data sources. However, in addition to low efficiency issues and high cost, there is often a single point of failure, resulting in low resiliency to faults and adversarial targeting.
abstract: ""

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2030-01-01T13:00:00Z"
date_end: "2030-01-01T15:00:00Z"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2017-01-01T00:00:00Z"

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: true

image:
  caption: ''
  focal_point: Right

url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides:

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
---
## Resilient Collaborative Machine Learning via Network-aware Knowledge Consensus
![concepts](https://user-images.githubusercontent.com/36635562/151391460-fe00b5d0-be13-4452-868e-5ca8623940cd.png)
#### **Novelty** 
- Knowledge similarity measure -
-  New convergence analysis
-  Plug-and-play collaborative learning framework 
- Knowledge support vectors.  <br>
#### **Advantages** 
- Consensus-based learning makes the proposed approach more natural for NTNs, since network communication is adaptive and significantly reduced.
- The plug-and-play framework increase scalability and resiliency to extreme events, including the complete loss of agents.

## Relevant paper
- [Large-Scale Resilient Collaborative Machine Learning](https://raslab.netlify.app/publication/lsrcml/) 
- [Concurrent Learning Adaptive Model Predictive Control with Pseudospectral Implementation](https://raslab.netlify.app/publication/clampcpi/)
- [Robust_Consensus Control for Leader-follower Networked System](https://github.com/ZYblend/Robust-Consensus-Control/blob/main/Robust_Consensus_formation_control.pdf)

